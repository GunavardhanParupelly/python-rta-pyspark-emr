2025-11-10 20:26:04,380 - utils.logger - INFO - ================================================================================
2025-11-10 20:26:04,382 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-10 20:26:04,382 - utils.logger - INFO - ================================================================================
2025-11-10 20:26:04,382 - utils.logger - INFO - Creating Spark session...
2025-11-10 20:26:08,402 - validate - WARNING - started the get_current_date method..
2025-11-10 20:26:12,230 - validate - WARNING - validation done , go frwd...
2025-11-10 20:26:12,230 - utils.logger - ERROR - Input directory not found: c:\Users\Gunav\Desktop\data\input
2025-11-10 20:27:13,630 - utils.logger - INFO - ================================================================================
2025-11-10 20:27:13,630 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-10 20:27:13,630 - utils.logger - INFO - ================================================================================
2025-11-10 20:27:13,630 - utils.logger - INFO - Creating Spark session...
2025-11-10 20:27:17,122 - validate - WARNING - started the get_current_date method..
2025-11-10 20:27:20,137 - validate - WARNING - validation done , go frwd...
2025-11-10 20:27:20,137 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-10 20:27:20,137 - ingest - WARNING - load_files method stared...
2025-11-10 20:27:21,914 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-10 20:27:21,914 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-10 20:27:22,162 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-10 20:27:22,957 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-10 20:27:22,957 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1762786642
2025-11-10 20:27:22,957 - transformation - INFO - Starting clean_and_stage()
2025-11-10 20:27:30,299 - transformation - INFO - Completed clean_and_stage()
2025-11-10 20:27:30,299 - transformation - INFO - Deriving emissionStandard
2025-11-10 20:27:31,657 - transformation - INFO - Generating surrogate keys
2025-11-10 20:27:32,904 - transformation - INFO - Building dimensions
2025-11-10 20:27:36,490 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-10 20:27:58,085 - transformation - INFO - Assembling fact table
2025-11-10 20:28:11,358 - transformation - INFO - Starting dynamic coalesce write to run_1762786642\gold_fact_registrations (format=parquet)
2025-11-10 20:28:35,417 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-10 20:28:35,417 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1762786642', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1762786642\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-10 20:28:35,417 - utils.logger - INFO - ================================================================================
2025-11-10 20:28:35,417 - utils.logger - INFO - Pipeline completed: 1 files processed in 81.78s
2025-11-10 20:28:35,417 - utils.logger - INFO - ================================================================================
2025-11-10 20:39:48,385 - root - WARNING - Logging config not found: c:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-10 20:39:48,385 - utils.logger - INFO - ================================================================================
2025-11-10 20:39:48,385 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-10 20:39:48,385 - utils.logger - INFO - ================================================================================
2025-11-10 20:39:48,385 - utils.logger - INFO - Creating Spark session...
2025-11-10 20:39:51,758 - validate - WARNING - started the get_current_date method..
2025-11-10 20:39:55,704 - validate - WARNING - validation done , go frwd...
2025-11-10 20:39:55,704 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-10 20:39:55,704 - ingest - WARNING - load_files method stared...
2025-11-10 20:39:57,864 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-10 20:39:57,864 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-10 20:39:58,136 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-10 20:39:59,094 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-10 20:39:59,094 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1762787399
2025-11-10 20:39:59,094 - transformation - INFO - Starting clean_and_stage()
2025-11-10 20:40:06,337 - transformation - INFO - Completed clean_and_stage()
2025-11-10 20:40:06,337 - transformation - INFO - Deriving emissionStandard
2025-11-10 20:40:07,543 - transformation - INFO - Generating surrogate keys
2025-11-10 20:40:08,629 - transformation - INFO - Building dimensions
2025-11-10 20:40:12,214 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-10 20:40:32,699 - transformation - INFO - Assembling fact table
2025-11-10 20:40:47,680 - transformation - INFO - Starting dynamic coalesce write to run_1762787399\gold_fact_registrations (format=parquet)
2025-11-10 20:41:14,394 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-10 20:41:14,394 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1762787399', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1762787399\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-10 20:41:14,394 - utils.logger - INFO - ================================================================================
2025-11-10 20:41:14,394 - utils.logger - INFO - Pipeline completed: 1 files processed in 86.00s
2025-11-10 20:41:14,394 - utils.logger - INFO - ================================================================================
2025-11-11 15:37:00,216 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-11 15:37:00,217 - utils.logger - INFO - ================================================================================
2025-11-11 15:37:00,217 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-11 15:37:00,217 - utils.logger - INFO - ================================================================================
2025-11-11 15:37:00,217 - utils.logger - INFO - Creating Spark session...
2025-11-11 15:37:03,382 - validate - WARNING - started the get_current_date method..
2025-11-11 15:37:06,699 - validate - WARNING - validation done , go frwd...
2025-11-11 15:37:06,699 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-11 15:37:06,699 - ingest - WARNING - load_files method stared...
2025-11-11 15:37:07,995 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-11 15:37:07,995 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-11 15:37:08,226 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-11 15:37:08,893 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-11 15:37:08,893 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1762855628
2025-11-11 15:37:08,893 - transformation - INFO - Starting clean_and_stage()
2025-11-11 15:37:14,959 - transformation - INFO - Completed clean_and_stage()
2025-11-11 15:37:14,959 - transformation - INFO - Deriving emissionStandard
2025-11-11 15:37:15,838 - transformation - INFO - Generating surrogate keys
2025-11-11 15:37:16,676 - transformation - INFO - Building dimensions
2025-11-11 15:37:20,149 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-11 15:37:42,472 - transformation - INFO - Assembling fact table
2025-11-11 15:37:56,460 - transformation - INFO - Starting dynamic coalesce write to run_1762855628\gold_fact_registrations (format=parquet)
2025-11-11 15:38:20,270 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-11 15:38:20,270 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1762855628', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1762855628\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-11 15:38:20,281 - utils.logger - INFO - ================================================================================
2025-11-11 15:38:20,297 - utils.logger - INFO - Pipeline completed: 1 files processed in 80.06s
2025-11-11 15:38:20,297 - utils.logger - INFO - ================================================================================
2025-11-12 16:33:04,400 - root - WARNING - Logging config not found: c:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-12 16:33:04,400 - utils.logger - INFO - ================================================================================
2025-11-12 16:33:04,400 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-12 16:33:04,400 - utils.logger - INFO - ================================================================================
2025-11-12 16:33:04,400 - utils.logger - INFO - Creating Spark session...
2025-11-12 16:33:07,873 - validate - WARNING - started the get_current_date method..
2025-11-12 16:33:12,016 - validate - WARNING - validation done , go frwd...
2025-11-12 16:33:12,016 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-12 16:33:12,016 - ingest - WARNING - load_files method stared...
2025-11-12 16:33:13,406 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-12 16:33:13,406 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-12 16:33:13,628 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-12 16:33:14,271 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-12 16:33:14,271 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1762945394
2025-11-12 16:33:14,271 - transformation - INFO - Starting clean_and_stage()
2025-11-12 16:33:20,404 - transformation - INFO - Completed clean_and_stage()
2025-11-12 16:33:20,405 - transformation - INFO - Deriving emissionStandard
2025-11-12 16:33:21,344 - transformation - INFO - Generating surrogate keys
2025-11-12 16:33:22,214 - transformation - INFO - Building dimensions
2025-11-12 16:33:26,416 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-12 16:33:50,540 - transformation - INFO - Assembling fact table
2025-11-12 16:34:05,167 - transformation - INFO - Starting dynamic coalesce write to run_1762945394\gold_fact_registrations (format=parquet)
2025-11-12 16:34:30,430 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-12 16:34:30,430 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1762945394', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1762945394\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-12 16:34:30,430 - utils.logger - INFO - ================================================================================
2025-11-12 16:34:30,430 - utils.logger - INFO - Pipeline completed: 1 files processed in 86.03s
2025-11-12 16:34:30,430 - utils.logger - INFO - ================================================================================
2025-11-14 21:09:05,559 - root - WARNING - Logging config not found: c:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:09:05,559 - utils.logger - INFO - ================================================================================
2025-11-14 21:09:05,559 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:09:05,559 - utils.logger - INFO - ================================================================================
2025-11-14 21:09:05,559 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:11:48,955 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:11:48,960 - utils.logger - INFO - ================================================================================
2025-11-14 21:11:48,962 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:11:48,962 - utils.logger - INFO - ================================================================================
2025-11-14 21:11:48,963 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:11:58,872 - validate - WARNING - started the get_current_date method..
2025-11-14 21:12:02,775 - validate - WARNING - validation done , go frwd...
2025-11-14 21:12:02,775 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:12:02,784 - ingest - WARNING - load_files method stared...
2025-11-14 21:12:04,865 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:12:04,865 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:12:05,194 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:12:06,321 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:12:06,321 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763134926
2025-11-14 21:12:06,321 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:12:13,890 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:12:13,890 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:12:15,245 - transformation - INFO - Generating surrogate keys
2025-11-14 21:12:16,728 - transformation - INFO - Building dimensions
2025-11-14 21:12:22,588 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:12:43,550 - transformation - INFO - Assembling fact table
2025-11-14 21:12:57,655 - transformation - INFO - Starting dynamic coalesce write to run_1763134926\gold_fact_registrations (format=parquet)
2025-11-14 21:13:20,856 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:13:20,865 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763134926', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1763134926\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-14 21:13:20,865 - utils.logger - INFO - ================================================================================
2025-11-14 21:13:20,865 - utils.logger - INFO - Pipeline completed: 1 files processed in 91.90s
2025-11-14 21:13:20,865 - utils.logger - INFO - ================================================================================
2025-11-14 21:16:01,243 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:16:01,243 - utils.logger - INFO - ================================================================================
2025-11-14 21:16:01,243 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:16:01,245 - utils.logger - INFO - ================================================================================
2025-11-14 21:16:01,245 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:16:05,749 - validate - WARNING - started the get_current_date method..
2025-11-14 21:16:05,749 - validate - WARNING - started the get_current_date method..
2025-11-14 21:16:10,523 - validate - WARNING - validation done , go frwd...
2025-11-14 21:16:10,523 - validate - WARNING - validation done , go frwd...
2025-11-14 21:16:10,523 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:16:10,523 - ingest - WARNING - load_files method stared...
2025-11-14 21:16:10,523 - ingest - WARNING - load_files method stared...
2025-11-14 21:16:12,364 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:16:12,364 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:16:12,364 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:16:12,364 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:16:12,776 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:16:12,776 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:16:13,837 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:16:13,837 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:16:13,837 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763135173
2025-11-14 21:16:13,837 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:16:13,837 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:16:23,024 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:16:23,024 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:16:23,026 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:16:23,026 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:16:24,445 - transformation - INFO - Generating surrogate keys
2025-11-14 21:16:24,445 - transformation - INFO - Generating surrogate keys
2025-11-14 21:16:25,676 - transformation - INFO - Building dimensions
2025-11-14 21:16:25,676 - transformation - INFO - Building dimensions
2025-11-14 21:16:29,532 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:16:29,532 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:16:36,837 - root - INFO - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending
2025-11-14 21:16:38,942 - transformation - ERROR - ETL failed: [WinError 10061] No connection could be made because the target machine actively refused it
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 430, in run_rta_etl_on_df
    resolved_map = fuzzy_vehicle_resolution(df_stage, dim_vehicle, metrics, fuzzy_threshold=fuzzy_threshold)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 301, in fuzzy_vehicle_resolution
    fuzzy_count = best_fuzzy.count()
                  ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    answer = self.gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 538, in send_command
    logger.info("Error while receiving.", exc_info=True)
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1479, in info
    def info(self, msg, *args, **kwargs):
    
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 377, in signal_handler
    self.cancelAllJobs()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 2255, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    answer = self.gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1053, in send_command
    response = self.send_command(command, binary=binary)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it
2025-11-14 21:16:38,942 - transformation - ERROR - ETL failed: [WinError 10061] No connection could be made because the target machine actively refused it
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 430, in run_rta_etl_on_df
    resolved_map = fuzzy_vehicle_resolution(df_stage, dim_vehicle, metrics, fuzzy_threshold=fuzzy_threshold)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 301, in fuzzy_vehicle_resolution
    fuzzy_count = best_fuzzy.count()
                  ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    answer = self.gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 538, in send_command
    logger.info("Error while receiving.", exc_info=True)
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1479, in info
    def info(self, msg, *args, **kwargs):
    
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 377, in signal_handler
    self.cancelAllJobs()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 2255, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    answer = self.gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1053, in send_command
    response = self.send_command(command, binary=binary)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it
2025-11-14 21:16:38,953 - utils.logger - ERROR - Failed to process telangana_transport_sales_jan_2019.csv: [WinError 10061] No connection could be made because the target machine actively refused it
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\driver.py", line 107, in main
    metrics = run_rta_etl_on_df(df, spark, run_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 430, in run_rta_etl_on_df
    resolved_map = fuzzy_vehicle_resolution(df_stage, dim_vehicle, metrics, fuzzy_threshold=fuzzy_threshold)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 301, in fuzzy_vehicle_resolution
    fuzzy_count = best_fuzzy.count()
                  ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    answer = self.gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 538, in send_command
    logger.info("Error while receiving.", exc_info=True)
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\logging\__init__.py", line 1479, in info
    def info(self, msg, *args, **kwargs):
    
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 377, in signal_handler
    self.cancelAllJobs()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 2255, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1321, in __call__
    answer = self.gateway_client.send_command(command)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1053, in send_command
    response = self.send_command(command, binary=binary)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1036, in send_command
    connection = self._get_connection()
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 284, in _get_connection
    connection = self._create_new_connection()
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 291, in _create_new_connection
    connection.connect_to_java_server()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 438, in connect_to_java_server
    self.socket.connect((self.java_address, self.java_port))
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it
2025-11-14 21:16:38,958 - utils.logger - INFO - ================================================================================
2025-11-14 21:16:38,958 - utils.logger - INFO - Pipeline completed: 0 files processed in 37.71s
2025-11-14 21:16:38,958 - utils.logger - INFO - ================================================================================
2025-11-14 21:16:39,894 - root - INFO - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 503, in send_command
    self.socket.sendall(command.encode("utf-8"))
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 506, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending
2025-11-14 21:20:06,878 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:20:06,878 - utils.logger - INFO - ================================================================================
2025-11-14 21:20:06,878 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:20:06,878 - utils.logger - INFO - ================================================================================
2025-11-14 21:20:06,878 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:20:10,933 - validate - WARNING - started the get_current_date method..
2025-11-14 21:20:10,933 - validate - WARNING - started the get_current_date method..
2025-11-14 21:20:14,262 - validate - WARNING - validation done , go frwd...
2025-11-14 21:20:14,262 - validate - WARNING - validation done , go frwd...
2025-11-14 21:20:14,263 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:20:14,263 - ingest - WARNING - load_files method stared...
2025-11-14 21:20:14,263 - ingest - WARNING - load_files method stared...
2025-11-14 21:20:16,160 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:20:16,160 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:20:16,164 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:20:16,164 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:20:16,421 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:20:16,421 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:20:17,285 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:20:17,285 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:20:17,285 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763135417
2025-11-14 21:20:17,285 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:20:17,285 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:20:24,543 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:20:24,543 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:20:24,543 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:20:24,543 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:20:25,754 - transformation - INFO - Generating surrogate keys
2025-11-14 21:20:25,754 - transformation - INFO - Generating surrogate keys
2025-11-14 21:20:27,058 - transformation - INFO - Building dimensions
2025-11-14 21:20:27,058 - transformation - INFO - Building dimensions
2025-11-14 21:20:30,707 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:20:30,707 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:20:49,738 - transformation - INFO - Assembling fact table
2025-11-14 21:20:49,738 - transformation - INFO - Assembling fact table
2025-11-14 21:21:02,883 - transformation - INFO - Starting dynamic coalesce write to run_1763135417\gold_fact_registrations (format=parquet)
2025-11-14 21:21:02,883 - transformation - INFO - Starting dynamic coalesce write to run_1763135417\gold_fact_registrations (format=parquet)
2025-11-14 21:21:28,673 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:21:28,673 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:21:28,674 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763135417', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1763135417\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-14 21:21:28,674 - utils.logger - INFO - ================================================================================
2025-11-14 21:21:28,674 - utils.logger - INFO - Pipeline completed: 1 files processed in 81.79s
2025-11-14 21:21:28,675 - utils.logger - INFO - ================================================================================
2025-11-14 21:25:28,737 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:25:28,737 - utils.logger - INFO - ================================================================================
2025-11-14 21:25:28,738 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:25:28,738 - utils.logger - INFO - ================================================================================
2025-11-14 21:25:28,738 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:25:31,963 - validate - WARNING - started the get_current_date method..
2025-11-14 21:25:31,963 - validate - WARNING - started the get_current_date method..
2025-11-14 21:25:35,026 - validate - WARNING - validation done , go frwd...
2025-11-14 21:25:35,026 - validate - WARNING - validation done , go frwd...
2025-11-14 21:25:35,026 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:25:35,027 - ingest - WARNING - load_files method stared...
2025-11-14 21:25:35,027 - ingest - WARNING - load_files method stared...
2025-11-14 21:25:36,384 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:25:36,384 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:25:36,384 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:25:36,384 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:25:36,619 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:25:36,619 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:25:37,200 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:25:37,200 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:25:37,201 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763135737
2025-11-14 21:25:37,203 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:25:37,203 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:25:42,734 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: reentrant call inside <_io.BufferedReader name=688>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-11-14 21:25:42,738 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 377, in signal_handler
    self.cancelAllJobs()
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\context.py", line 2255, in cancelAllJobs
    self._jsc.sc().cancelAllJobs()
    ^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o18.sc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-11-14 21:25:42,773 - transformation - ERROR - ETL failed: An error occurred while calling o238.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 426, in run_rta_etl_on_df
    df_stage = clean_and_stage(df_raw, metrics, bad_root, output_format=output_format)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 160, in clean_and_stage
    invalid_dates_cnt = invalid_dates.count()
                        ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o238.count
2025-11-14 21:25:42,773 - transformation - ERROR - ETL failed: An error occurred while calling o238.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 426, in run_rta_etl_on_df
    df_stage = clean_and_stage(df_raw, metrics, bad_root, output_format=output_format)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 160, in clean_and_stage
    invalid_dates_cnt = invalid_dates.count()
                        ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o238.count
2025-11-14 21:25:42,775 - utils.logger - ERROR - Failed to process telangana_transport_sales_jan_2019.csv: An error occurred while calling o238.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\driver.py", line 107, in main
    metrics = run_rta_etl_on_df(df, spark, run_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 426, in run_rta_etl_on_df
    df_stage = clean_and_stage(df_raw, metrics, bad_root, output_format=output_format)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 160, in clean_and_stage
    invalid_dates_cnt = invalid_dates.count()
                        ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o238.count
2025-11-14 21:25:42,776 - utils.logger - INFO - ================================================================================
2025-11-14 21:25:42,776 - utils.logger - INFO - Pipeline completed: 0 files processed in 14.04s
2025-11-14 21:25:42,777 - utils.logger - INFO - ================================================================================
2025-11-14 21:25:43,348 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-11-14 21:26:32,689 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:26:32,689 - utils.logger - INFO - ================================================================================
2025-11-14 21:26:32,689 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:26:32,690 - utils.logger - INFO - ================================================================================
2025-11-14 21:26:32,690 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:26:35,887 - validate - WARNING - started the get_current_date method..
2025-11-14 21:26:35,887 - validate - WARNING - started the get_current_date method..
2025-11-14 21:26:39,067 - validate - WARNING - validation done , go frwd...
2025-11-14 21:26:39,067 - validate - WARNING - validation done , go frwd...
2025-11-14 21:26:39,068 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:26:39,068 - ingest - WARNING - load_files method stared...
2025-11-14 21:26:39,068 - ingest - WARNING - load_files method stared...
2025-11-14 21:26:40,319 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:26:40,319 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:26:40,320 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:26:40,320 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:26:40,547 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:26:40,547 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:26:41,188 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:26:41,188 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:26:41,188 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763135801
2025-11-14 21:26:41,189 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:26:41,189 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:26:46,852 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:26:46,852 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:26:46,852 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:26:46,852 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:26:48,016 - transformation - INFO - Generating surrogate keys
2025-11-14 21:26:48,016 - transformation - INFO - Generating surrogate keys
2025-11-14 21:26:49,301 - transformation - INFO - Building dimensions
2025-11-14 21:26:49,301 - transformation - INFO - Building dimensions
2025-11-14 21:26:54,510 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:26:54,510 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:27:18,528 - transformation - INFO - Assembling fact table
2025-11-14 21:27:18,528 - transformation - INFO - Assembling fact table
2025-11-14 21:27:19,925 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-11-14 21:27:19,928 - transformation - ERROR - ETL failed: An error occurred while calling o615.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 431, in run_rta_etl_on_df
    fact_df = assemble_fact_table(df_stage, resolved_map, metrics)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 337, in assemble_fact_table
    after = fact_df.count()
            ^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o615.count
2025-11-14 21:27:19,928 - transformation - ERROR - ETL failed: An error occurred while calling o615.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 431, in run_rta_etl_on_df
    fact_df = assemble_fact_table(df_stage, resolved_map, metrics)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 337, in assemble_fact_table
    after = fact_df.count()
            ^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o615.count
2025-11-14 21:27:19,934 - utils.logger - ERROR - Failed to process telangana_transport_sales_jan_2019.csv: An error occurred while calling o615.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\driver.py", line 107, in main
    metrics = run_rta_etl_on_df(df, spark, run_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 431, in run_rta_etl_on_df
    fact_df = assemble_fact_table(df_stage, resolved_map, metrics)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 337, in assemble_fact_table
    after = fact_df.count()
            ^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o615.count
2025-11-14 21:27:19,937 - utils.logger - INFO - ================================================================================
2025-11-14 21:27:19,937 - utils.logger - INFO - Pipeline completed: 0 files processed in 47.25s
2025-11-14 21:27:19,937 - utils.logger - INFO - ================================================================================
2025-11-14 21:27:47,059 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:27:47,060 - utils.logger - INFO - ================================================================================
2025-11-14 21:27:47,060 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:27:47,060 - utils.logger - INFO - ================================================================================
2025-11-14 21:27:47,060 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:27:51,718 - validate - WARNING - started the get_current_date method..
2025-11-14 21:27:51,718 - validate - WARNING - started the get_current_date method..
2025-11-14 21:27:57,128 - validate - WARNING - validation done , go frwd...
2025-11-14 21:27:57,128 - validate - WARNING - validation done , go frwd...
2025-11-14 21:27:57,129 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:27:57,130 - ingest - WARNING - load_files method stared...
2025-11-14 21:27:57,130 - ingest - WARNING - load_files method stared...
2025-11-14 21:27:59,150 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:27:59,150 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:27:59,151 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:27:59,151 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:27:59,557 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:27:59,557 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:28:00,601 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:28:00,601 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:28:00,602 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763135880
2025-11-14 21:28:00,602 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:28:00,602 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:28:09,351 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:28:09,351 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:28:09,352 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:28:09,352 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:28:10,907 - transformation - INFO - Generating surrogate keys
2025-11-14 21:28:10,907 - transformation - INFO - Generating surrogate keys
2025-11-14 21:28:12,616 - transformation - INFO - Building dimensions
2025-11-14 21:28:12,616 - transformation - INFO - Building dimensions
2025-11-14 21:28:19,125 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:28:19,125 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:28:43,905 - transformation - INFO - Assembling fact table
2025-11-14 21:28:43,905 - transformation - INFO - Assembling fact table
2025-11-14 21:29:01,924 - transformation - INFO - Starting dynamic coalesce write to run_1763135880\gold_fact_registrations (format=parquet)
2025-11-14 21:29:01,924 - transformation - INFO - Starting dynamic coalesce write to run_1763135880\gold_fact_registrations (format=parquet)
2025-11-14 21:29:30,488 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:29:30,488 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:29:30,489 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763135880', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1763135880\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-14 21:29:30,489 - utils.logger - INFO - ================================================================================
2025-11-14 21:29:30,490 - utils.logger - INFO - Pipeline completed: 1 files processed in 103.43s
2025-11-14 21:29:30,490 - utils.logger - INFO - ================================================================================
2025-11-14 21:31:33,423 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:31:33,423 - utils.logger - INFO - ================================================================================
2025-11-14 21:31:33,424 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:31:33,424 - utils.logger - INFO - ================================================================================
2025-11-14 21:31:33,424 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:31:36,949 - validate - WARNING - started the get_current_date method..
2025-11-14 21:31:36,949 - validate - WARNING - started the get_current_date method..
2025-11-14 21:31:40,228 - validate - WARNING - validation done , go frwd...
2025-11-14 21:31:40,228 - validate - WARNING - validation done , go frwd...
2025-11-14 21:31:40,230 - utils.logger - INFO - Processing file: transport_2019-01.csv (format: csv)
2025-11-14 21:31:40,230 - ingest - WARNING - load_files method stared...
2025-11-14 21:31:40,230 - ingest - WARNING - load_files method stared...
2025-11-14 21:31:41,858 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:31:41,858 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:31:41,859 - ingest - INFO - Displaying DataFrame: df_transport_2019-01.csv
2025-11-14 21:31:41,859 - ingest - INFO - Displaying DataFrame: df_transport_2019-01.csv
2025-11-14 21:31:42,411 - ingest - WARNING - here to count the records in the df_transport_2019-01.csv
2025-11-14 21:31:42,411 - ingest - WARNING - here to count the records in the df_transport_2019-01.csv
2025-11-14 21:31:43,686 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:31:43,686 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:31:43,687 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763136103
2025-11-14 21:31:43,688 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:31:43,688 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:31:55,240 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:31:55,240 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:31:55,242 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:31:55,242 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:31:57,487 - transformation - INFO - Generating surrogate keys
2025-11-14 21:31:57,487 - transformation - INFO - Generating surrogate keys
2025-11-14 21:31:59,175 - transformation - INFO - Building dimensions
2025-11-14 21:31:59,175 - transformation - INFO - Building dimensions
2025-11-14 21:32:04,734 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:32:04,734 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:32:31,640 - transformation - INFO - Assembling fact table
2025-11-14 21:32:31,640 - transformation - INFO - Assembling fact table
2025-11-14 21:32:47,591 - transformation - INFO - Starting dynamic coalesce write to run_1763136103\gold_fact_registrations (format=parquet)
2025-11-14 21:32:47,591 - transformation - INFO - Starting dynamic coalesce write to run_1763136103\gold_fact_registrations (format=parquet)
2025-11-14 21:33:20,325 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:33:20,325 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:33:20,326 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763136103', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1763136103\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3052142}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-14 21:33:20,326 - utils.logger - INFO - Processing file: transport_2019-02.csv (format: csv)
2025-11-14 21:33:20,327 - ingest - WARNING - load_files method stared...
2025-11-14 21:33:20,327 - ingest - WARNING - load_files method stared...
2025-11-14 21:33:20,950 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:33:20,950 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:33:20,951 - ingest - INFO - Displaying DataFrame: df_transport_2019-02.csv
2025-11-14 21:33:20,951 - ingest - INFO - Displaying DataFrame: df_transport_2019-02.csv
2025-11-14 21:33:21,104 - ingest - WARNING - here to count the records in the df_transport_2019-02.csv
2025-11-14 21:33:21,104 - ingest - WARNING - here to count the records in the df_transport_2019-02.csv
2025-11-14 21:33:21,336 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 182863
2025-11-14 21:33:21,336 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 182863
2025-11-14 21:33:21,336 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763136201
2025-11-14 21:33:21,337 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:33:21,337 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:33:26,663 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:33:26,663 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:33:26,664 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:33:26,664 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:33:28,206 - transformation - INFO - Generating surrogate keys
2025-11-14 21:33:28,206 - transformation - INFO - Generating surrogate keys
2025-11-14 21:33:29,443 - transformation - INFO - Building dimensions
2025-11-14 21:33:29,443 - transformation - INFO - Building dimensions
2025-11-14 21:33:32,293 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:33:32,293 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:33:53,926 - transformation - INFO - Assembling fact table
2025-11-14 21:33:53,926 - transformation - INFO - Assembling fact table
2025-11-14 21:34:07,116 - transformation - INFO - Starting dynamic coalesce write to run_1763136201\gold_fact_registrations (format=parquet)
2025-11-14 21:34:07,116 - transformation - INFO - Starting dynamic coalesce write to run_1763136201\gold_fact_registrations (format=parquet)
2025-11-14 21:34:35,780 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:34:35,780 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:34:35,780 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763136201', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 182863, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95690, 'deduplicated_rows': 87173, 'invalid_dates': 0, 'staged_rows': 95690}, 'derive_emission_standard': {'before': 95690, 'after': 95690}, 'generate_surrogate_keys': {'before': 95690, 'after': 95690}, 'build_dimensions': {'dim_vehicle_count': 5437, 'dim_manufacturer_count': 387, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95690, 'fuzzy_matches': 0, 'total_resolved': 95690}, 'assemble_fact_table': {'before': 95690, 'after': 95690}}, 'writes': {'fact': {'path': 'run_1763136201\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3072192}}, 'final_counts': {'dim_vehicle': 5437, 'dim_manufacturer': 387, 'dim_rta': 53, 'fact_rows': 95690}}
2025-11-14 21:34:35,780 - utils.logger - INFO - Processing file: transport_2019-03.csv (format: csv)
2025-11-14 21:34:35,782 - ingest - WARNING - load_files method stared...
2025-11-14 21:34:35,782 - ingest - WARNING - load_files method stared...
2025-11-14 21:34:36,173 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:34:36,173 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:34:36,174 - ingest - INFO - Displaying DataFrame: df_transport_2019-03.csv
2025-11-14 21:34:36,174 - ingest - INFO - Displaying DataFrame: df_transport_2019-03.csv
2025-11-14 21:34:36,313 - ingest - WARNING - here to count the records in the df_transport_2019-03.csv
2025-11-14 21:34:36,313 - ingest - WARNING - here to count the records in the df_transport_2019-03.csv
2025-11-14 21:34:36,515 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 198926
2025-11-14 21:34:36,515 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 198926
2025-11-14 21:34:36,516 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763136276
2025-11-14 21:34:36,517 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:34:36,517 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:34:40,878 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:34:40,878 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:34:40,878 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:34:40,878 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:34:42,435 - transformation - INFO - Generating surrogate keys
2025-11-14 21:34:42,435 - transformation - INFO - Generating surrogate keys
2025-11-14 21:34:43,943 - transformation - INFO - Building dimensions
2025-11-14 21:34:43,943 - transformation - INFO - Building dimensions
2025-11-14 21:34:47,256 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:34:47,256 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:35:14,736 - transformation - INFO - Assembling fact table
2025-11-14 21:35:14,736 - transformation - INFO - Assembling fact table
2025-11-14 21:35:34,882 - transformation - INFO - Starting dynamic coalesce write to run_1763136276\gold_fact_registrations (format=parquet)
2025-11-14 21:35:34,882 - transformation - INFO - Starting dynamic coalesce write to run_1763136276\gold_fact_registrations (format=parquet)
2025-11-14 21:36:05,148 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:36:05,148 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:36:05,148 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763136276', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 198926, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 103132, 'deduplicated_rows': 95794, 'invalid_dates': 0, 'staged_rows': 103132}, 'derive_emission_standard': {'before': 103132, 'after': 103132}, 'generate_surrogate_keys': {'before': 103132, 'after': 103132}, 'build_dimensions': {'dim_vehicle_count': 6011, 'dim_manufacturer_count': 403, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 103132, 'fuzzy_matches': 0, 'total_resolved': 103132}, 'assemble_fact_table': {'before': 103132, 'after': 103132}}, 'writes': {'fact': {'path': 'run_1763136276\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3360309}}, 'final_counts': {'dim_vehicle': 6011, 'dim_manufacturer': 403, 'dim_rta': 53, 'fact_rows': 103132}}
2025-11-14 21:36:05,148 - utils.logger - INFO - Processing file: transport_2019-04.csv (format: csv)
2025-11-14 21:36:05,148 - ingest - WARNING - load_files method stared...
2025-11-14 21:36:05,148 - ingest - WARNING - load_files method stared...
2025-11-14 21:36:05,391 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:36:05,391 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:36:05,391 - ingest - INFO - Displaying DataFrame: df_transport_2019-04.csv
2025-11-14 21:36:05,391 - ingest - INFO - Displaying DataFrame: df_transport_2019-04.csv
2025-11-14 21:36:05,462 - ingest - WARNING - here to count the records in the df_transport_2019-04.csv
2025-11-14 21:36:05,462 - ingest - WARNING - here to count the records in the df_transport_2019-04.csv
2025-11-14 21:36:05,583 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 168661
2025-11-14 21:36:05,583 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 168661
2025-11-14 21:36:05,585 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763136365
2025-11-14 21:36:05,585 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:36:05,585 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:36:10,166 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:36:10,166 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:36:10,167 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:36:10,167 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:36:11,895 - transformation - INFO - Generating surrogate keys
2025-11-14 21:36:11,895 - transformation - INFO - Generating surrogate keys
2025-11-14 21:36:13,641 - transformation - INFO - Building dimensions
2025-11-14 21:36:13,641 - transformation - INFO - Building dimensions
2025-11-14 21:36:17,105 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:36:17,105 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:36:38,949 - transformation - INFO - Assembling fact table
2025-11-14 21:36:38,949 - transformation - INFO - Assembling fact table
2025-11-14 21:36:54,094 - transformation - INFO - Starting dynamic coalesce write to run_1763136365\gold_fact_registrations (format=parquet)
2025-11-14 21:36:54,094 - transformation - INFO - Starting dynamic coalesce write to run_1763136365\gold_fact_registrations (format=parquet)
2025-11-14 21:37:18,192 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:37:18,192 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:37:18,192 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763136365', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 168661, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 87660, 'deduplicated_rows': 81001, 'invalid_dates': 0, 'staged_rows': 87660}, 'derive_emission_standard': {'before': 87660, 'after': 87660}, 'generate_surrogate_keys': {'before': 87660, 'after': 87660}, 'build_dimensions': {'dim_vehicle_count': 5321, 'dim_manufacturer_count': 369, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 87660, 'fuzzy_matches': 0, 'total_resolved': 87660}, 'assemble_fact_table': {'before': 87660, 'after': 87660}}, 'writes': {'fact': {'path': 'run_1763136365\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 2884737}}, 'final_counts': {'dim_vehicle': 5321, 'dim_manufacturer': 369, 'dim_rta': 53, 'fact_rows': 87660}}
2025-11-14 21:37:18,193 - utils.logger - INFO - Processing file: transport_2019-05.csv (format: csv)
2025-11-14 21:37:18,193 - ingest - WARNING - load_files method stared...
2025-11-14 21:37:18,193 - ingest - WARNING - load_files method stared...
2025-11-14 21:37:18,542 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:37:18,542 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:37:18,542 - ingest - INFO - Displaying DataFrame: df_transport_2019-05.csv
2025-11-14 21:37:18,542 - ingest - INFO - Displaying DataFrame: df_transport_2019-05.csv
2025-11-14 21:37:18,625 - ingest - WARNING - here to count the records in the df_transport_2019-05.csv
2025-11-14 21:37:18,625 - ingest - WARNING - here to count the records in the df_transport_2019-05.csv
2025-11-14 21:37:18,773 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 173807
2025-11-14 21:37:18,773 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 173807
2025-11-14 21:37:18,774 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763136438
2025-11-14 21:37:18,774 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:37:18,774 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:37:23,381 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:37:23,381 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:37:23,383 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:37:23,383 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:37:24,782 - transformation - INFO - Generating surrogate keys
2025-11-14 21:37:24,782 - transformation - INFO - Generating surrogate keys
2025-11-14 21:37:26,149 - transformation - INFO - Building dimensions
2025-11-14 21:37:26,149 - transformation - INFO - Building dimensions
2025-11-14 21:37:28,654 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:37:28,654 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:37:50,077 - transformation - INFO - Assembling fact table
2025-11-14 21:37:50,077 - transformation - INFO - Assembling fact table
2025-11-14 21:38:04,364 - transformation - INFO - Starting dynamic coalesce write to run_1763136438\gold_fact_registrations (format=parquet)
2025-11-14 21:38:04,364 - transformation - INFO - Starting dynamic coalesce write to run_1763136438\gold_fact_registrations (format=parquet)
2025-11-14 21:38:35,465 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:38:35,465 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 21:38:35,466 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763136438', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 173807, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 89478, 'deduplicated_rows': 84329, 'invalid_dates': 0, 'staged_rows': 89478}, 'derive_emission_standard': {'before': 89478, 'after': 89478}, 'generate_surrogate_keys': {'before': 89478, 'after': 89478}, 'build_dimensions': {'dim_vehicle_count': 5402, 'dim_manufacturer_count': 355, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 89478, 'fuzzy_matches': 0, 'total_resolved': 89478}, 'assemble_fact_table': {'before': 89478, 'after': 89478}}, 'writes': {'fact': {'path': 'run_1763136438\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 2919890}}, 'final_counts': {'dim_vehicle': 5402, 'dim_manufacturer': 355, 'dim_rta': 53, 'fact_rows': 89478}}
2025-11-14 21:38:35,467 - utils.logger - INFO - Processing file: transport_2019-06.csv (format: csv)
2025-11-14 21:38:35,467 - ingest - WARNING - load_files method stared...
2025-11-14 21:38:35,467 - ingest - WARNING - load_files method stared...
2025-11-14 21:38:36,026 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:38:36,026 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:38:36,026 - ingest - INFO - Displaying DataFrame: df_transport_2019-06.csv
2025-11-14 21:38:36,026 - ingest - INFO - Displaying DataFrame: df_transport_2019-06.csv
2025-11-14 21:38:36,122 - ingest - WARNING - here to count the records in the df_transport_2019-06.csv
2025-11-14 21:38:36,122 - ingest - WARNING - here to count the records in the df_transport_2019-06.csv
2025-11-14 21:38:36,323 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 175312
2025-11-14 21:38:36,323 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 175312
2025-11-14 21:38:36,323 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763136516
2025-11-14 21:38:36,323 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:38:36,323 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:38:44,262 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:38:44,262 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:38:44,262 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:38:44,262 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:38:46,656 - transformation - INFO - Generating surrogate keys
2025-11-14 21:38:46,656 - transformation - INFO - Generating surrogate keys
2025-11-14 21:38:48,598 - transformation - INFO - Building dimensions
2025-11-14 21:38:48,598 - transformation - INFO - Building dimensions
2025-11-14 21:38:51,489 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:38:51,489 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:38:53,919 - root - ERROR - Exception while sending command.
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
                          ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
2025-11-14 21:38:53,932 - transformation - ERROR - ETL failed: An error occurred while calling o3475.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 430, in run_rta_etl_on_df
    resolved_map = fuzzy_vehicle_resolution(df_stage, dim_vehicle, metrics, fuzzy_threshold=fuzzy_threshold)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 273, in fuzzy_vehicle_resolution
    exact_count = resolved_exact.count()
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o3475.count
2025-11-14 21:38:53,932 - transformation - ERROR - ETL failed: An error occurred while calling o3475.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 430, in run_rta_etl_on_df
    resolved_map = fuzzy_vehicle_resolution(df_stage, dim_vehicle, metrics, fuzzy_threshold=fuzzy_threshold)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 273, in fuzzy_vehicle_resolution
    exact_count = resolved_exact.count()
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o3475.count
2025-11-14 21:38:53,939 - utils.logger - ERROR - Failed to process transport_2019-06.csv: An error occurred while calling o3475.count
Traceback (most recent call last):
  File "C:\Users\Gunav\Desktop\spark1-master\driver.py", line 107, in main
    metrics = run_rta_etl_on_df(df, spark, run_id)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 430, in run_rta_etl_on_df
    resolved_map = fuzzy_vehicle_resolution(df_stage, dim_vehicle, metrics, fuzzy_threshold=fuzzy_threshold)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\src\core\transformation.py", line 273, in fuzzy_vehicle_resolution
    exact_count = resolved_exact.count()
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\sql\dataframe.py", line 1193, in count
    return int(self._jdf.count())
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\java_gateway.py", line 1322, in __call__
    return_value = get_return_value(
                   ^^^^^^^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\pyspark\errors\exceptions\captured.py", line 169, in deco
    return f(*a, **kw)
           ^^^^^^^^^^^
  File "C:\Users\Gunav\Desktop\spark1-master\sparl1locanvenv\Lib\site-packages\py4j\protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling o3475.count
2025-11-14 21:38:53,942 - utils.logger - INFO - Processing file: transport_2019-07.csv (format: csv)
2025-11-14 21:38:53,942 - ingest - WARNING - load_files method stared...
2025-11-14 21:38:53,942 - ingest - WARNING - load_files method stared...
2025-11-14 21:58:34,526 - root - WARNING - Logging config not found: C:\Users\Gunav\Desktop\spark1-master\config\logging.config
2025-11-14 21:58:34,527 - utils.logger - INFO - ================================================================================
2025-11-14 21:58:34,527 - utils.logger - INFO - Starting RTA ETL Pipeline
2025-11-14 21:58:34,527 - utils.logger - INFO - ================================================================================
2025-11-14 21:58:34,527 - utils.logger - INFO - Creating Spark session...
2025-11-14 21:58:38,483 - validate - WARNING - started the get_current_date method..
2025-11-14 21:58:38,483 - validate - WARNING - started the get_current_date method..
2025-11-14 21:58:42,835 - validate - WARNING - validation done , go frwd...
2025-11-14 21:58:42,835 - validate - WARNING - validation done , go frwd...
2025-11-14 21:58:42,836 - utils.logger - INFO - Processing file: telangana_transport_sales_jan_2019.csv (format: csv)
2025-11-14 21:58:42,836 - ingest - WARNING - load_files method stared...
2025-11-14 21:58:42,836 - ingest - WARNING - load_files method stared...
2025-11-14 21:58:44,430 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:58:44,430 - ingest - WARNING - dataframe created sucessfully which is of csv
2025-11-14 21:58:44,431 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:58:44,431 - ingest - INFO - Displaying DataFrame: df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:58:44,681 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:58:44,681 - ingest - WARNING - here to count the records in the df_telangana_transport_sales_jan_2019.csv
2025-11-14 21:58:45,541 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:58:45,541 - ingest - WARNING - Number of records present in the DataFrame[slno: int, modelDesc: string, fuel: string, colour: string, vehicleClass: string, makeYear: string, seatCapacity: int, secondVehicle: string, tempRegistrationNumber: string, category: string, makerName: string, OfficeCd: string, fromdate: string, todate: string] are :: 184665
2025-11-14 21:58:45,542 - utils.logger - INFO - Starting ETL pipeline with run_id: run_1763137725
2025-11-14 21:58:45,542 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:58:45,542 - transformation - INFO - Starting clean_and_stage()
2025-11-14 21:58:56,208 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:58:56,208 - transformation - INFO - Completed clean_and_stage()
2025-11-14 21:58:56,209 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:58:56,209 - transformation - INFO - Deriving emissionStandard
2025-11-14 21:58:58,010 - transformation - INFO - Generating surrogate keys
2025-11-14 21:58:58,010 - transformation - INFO - Generating surrogate keys
2025-11-14 21:58:59,838 - transformation - INFO - Building dimensions
2025-11-14 21:58:59,838 - transformation - INFO - Building dimensions
2025-11-14 21:59:05,842 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:59:05,842 - transformation - INFO - Running exact + fuzzy vehicle resolution
2025-11-14 21:59:32,126 - transformation - INFO - Assembling fact table
2025-11-14 21:59:32,126 - transformation - INFO - Assembling fact table
2025-11-14 21:59:49,687 - transformation - INFO - Starting dynamic coalesce write to run_1763137725\gold_fact_registrations (format=parquet)
2025-11-14 21:59:49,687 - transformation - INFO - Starting dynamic coalesce write to run_1763137725\gold_fact_registrations (format=parquet)
2025-11-14 22:00:19,076 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 22:00:19,076 - transformation - INFO - RTA ETL on dataframe completed successfully.
2025-11-14 22:00:19,076 - utils.logger - INFO - ETL completed. Metrics: {'run_id': None, 'config': {'output_root': 'run_1763137725', 'mode': 'overwrite', 'target_mb': 128.0}, 'steps': {'clean_and_stage': {'before': 184665, 'missing_tempRegistrationNumber': 0, 'after_dedupe': 95519, 'deduplicated_rows': 89146, 'invalid_dates': 0, 'staged_rows': 95519}, 'derive_emission_standard': {'before': 95519, 'after': 95519}, 'generate_surrogate_keys': {'before': 95519, 'after': 95519}, 'build_dimensions': {'dim_vehicle_count': 5535, 'dim_manufacturer_count': 372, 'dim_rta_count': 53}, 'fuzzy_vehicle_resolution': {'exact_matches': 95519, 'fuzzy_matches': 0, 'total_resolved': 95519}, 'assemble_fact_table': {'before': 95519, 'after': 95519}}, 'writes': {'fact': {'path': 'run_1763137725\\gold_fact_registrations', 'coalesced_parts': 1, 'bytes': 3024235}}, 'final_counts': {'dim_vehicle': 5535, 'dim_manufacturer': 372, 'dim_rta': 53, 'fact_rows': 95519}}
2025-11-14 22:00:19,076 - utils.logger - INFO - ================================================================================
2025-11-14 22:00:19,078 - utils.logger - INFO - Pipeline completed: 1 files processed in 104.55s
2025-11-14 22:00:19,078 - utils.logger - INFO - ================================================================================
